{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>TUGAS HANDS-ON 1</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center>Sikah Nubuahtul Ilmi</center>  \n",
    "<center>NIM: 122140208</center>\n",
    "\n",
    "---\n",
    "\n",
    "📁 Repository GitHub:\n",
    "🔗 [Link GitHub](https://github.com/sigawari/handson-1-if4021)\n",
    "\n",
    "🔊 Audio Input (Berita.wav):\n",
    "🎵 [File_Audio_HandsOn1](https://drive.google.com/drive/folders/1gPmMH7YiiDmYg40ca8kqykiKrwCnD-zK?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎧 Soal 1: Visualisasi Audio 20 Detik\n",
    "\n",
    "### 🎙️ Proses Rekaman:\n",
    "Saya merekam suara saya sendiri selama **25-26 detik**, dengan membaca sebuah teks berita dan melakukan variasi volume serta gaya suara sesuai instruksi berikut:\n",
    "\n",
    "- ⏱️ **Detik 1–5**: Saya membaca dengan **suara sangat pelan / berbisik**\n",
    "- ⏱️ **Detik 6–10**: Saya membaca dengan **suara normal**\n",
    "- ⏱️ **Detik 11–15**: Saya membaca dengan **suara keras**\n",
    "- ⏱️ **Detik 16–20**: Saya membaca dengan **suara cempreng atau dibuat-buat cempreng**\n",
    "- ⏱️ **Detik 20–25**: Saya membaca dengan **suara berteriak**\n",
    "\n",
    "---\n",
    "\n",
    "### 🎼 Format Rekaman:\n",
    "Saya menyimpan rekaman dalam format **`.wav`**. Apabila rekaman saya berada dalam format lain (seperti `.mp3`), saya mengonversinya terlebih dahulu ke `.wav` sebelum memuatnya ke dalam notebook. Audio yang saya rekam saya sesuaikan lagi agar sesuai dengan spek yang diminta.\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 Proses Visualisasi:\n",
    "1. Saya memuat file audio `.wav` ke dalam notebook\n",
    "2. Saya melakukan visualisasi dalam dua bentuk:\n",
    "   - **Waveform** (amplitudo terhadap waktu)\n",
    "   - **Spektogram** (frekuensi terhadap waktu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wave\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(), 'file_audio', 'berita.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with wave.open(file_path, 'r') as wav_file:\n",
    "    frames = wav_file.readframes(-1)\n",
    "    sound_info = np.frombuffer(frames, dtype=np.int16)\n",
    "    frame_rate = wav_file.getframerate()\n",
    "    time = np.linspace(0, len(sound_info) / frame_rate, num=len(sound_info))\n",
    "\n",
    "    plt.figure(figsize=(22, 6))\n",
    "    plt.plot(time, sound_info, color=\"#1DB954\", linewidth=1.2, alpha=0.8)\n",
    "\n",
    "    plt.title('Waveform Audio: Membaca Berita 25 Detik', fontsize=20, fontweight='bold', color=\"#333333\")\n",
    "    plt.xlabel('Waktu (detik)', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Amplitudo', fontsize=14, fontweight='bold')\n",
    "\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.3, color='#888888', alpha=0.6)\n",
    "    plt.gca().set_facecolor('#F9F9F9')\n",
    "    plt.gcf().patch.set_facecolor('#FFFFFF')\n",
    "\n",
    "    plt.axhline(y=0, color='gray', linestyle='-', linewidth=0.7)\n",
    "    plt.fill_between(time, sound_info, color=\"#1DB954\", alpha=0.1)  # Area fill\n",
    "\n",
    "    max_amp = np.max(sound_info)\n",
    "    max_time = time[np.argmax(sound_info)]\n",
    "    plt.annotate('Puncak Amplitudo',\n",
    "                 xy=(max_time, max_amp),\n",
    "                 xytext=(max_time + 0.5, max_amp + 1000),\n",
    "                 arrowprops=dict(facecolor='orange', shrink=0.05),\n",
    "                 fontsize=12, color='black', fontweight='bold')\n",
    "\n",
    "    # Tampilan rapih\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitung spektogram\n",
    "plt.figure(figsize=(22, 6))\n",
    "S = librosa.stft(y)\n",
    "S_db = librosa.amplitude_to_db(np.abs(S), ref=np.max)\n",
    "\n",
    "# Tampilkan spektogram\n",
    "librosa.display.specshow(\n",
    "    S_db,\n",
    "    sr=sr,\n",
    "    x_axis='time',\n",
    "    y_axis='log',\n",
    "    cmap='magma'\n",
    ")\n",
    "\n",
    "# Tambahkan colorbar yang informatif\n",
    "cbar = plt.colorbar(format='%+2.0f dB')\n",
    "cbar.set_label('Intensitas (dB)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Tambahkan detail visual\n",
    "plt.title('Spektogram Audio: Membaca Berita 25 Detik', fontsize=20, fontweight='bold', color='#333')\n",
    "plt.xlabel('Waktu (detik)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Frekuensi (log scale)', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.gca().set_facecolor('#FDFDFD')\n",
    "plt.gcf().patch.set_facecolor('#FFFFFF')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📝 Analisis Singkat:\n",
    "\n",
    "1. 🎚️ **Waveform**\n",
    "\n",
    "- **0–5 detik (Suara Berbisik)**  \n",
    "  Amplitudo sangat rendah, hampir mendekati garis nol, dengan gelombang tipis yang menunjukkan suara pelan.\n",
    "\n",
    "- **5–10 detik (Suara Normal)**  \n",
    "  Amplitudo meningkat secara moderat, gelombang lebih padat dan teratur.\n",
    "\n",
    "- **10–15 detik (Suara Keras)**  \n",
    "  Amplitudo meningkat pesat, dengan gelombang besar dan padat, menunjukkan suara yang kuat.\n",
    "\n",
    "- **15–20 detik (Suara Cempreng)**  \n",
    "  Terdapat puncak amplitudo yang tinggi, dengan gelombang yang lebih tajam dan kadang menyentak.\n",
    "\n",
    "- **20 detik ke atas (Suara Berteriak)**  \n",
    "  Amplitudo sangat besar dan mendekati kliping, menunjukkan kemungkinan distorsi pada audio.\n",
    "\n",
    "---\n",
    "2. 🌈 **Spektrogram**\n",
    "\n",
    "- **0–5 detik (Suara Berbisik)**  \n",
    "  Intensitas rendah, hanya frekuensi rendah yang terlihat samar.\n",
    "\n",
    "- **5–10 detik (Suara Normal)**  \n",
    "  Frekuensi mulai lebih beragam, intensitas meningkat, tampak warna lebih terang.\n",
    "\n",
    "- **10–15 detik (Suara Keras)**  \n",
    "  Banyak frekuensi tinggi muncul, intensitas mulai terang dan menyebar ke atas.\n",
    "\n",
    "- **15–20 detik (Suara Cempreng)**  \n",
    "  Banyak frekuensi tinggi diaktifkan, dengan intensitas maksimal dan pola tajam.\n",
    "\n",
    "- **20 detik ke atas (Suara Berteriak)**  \n",
    "  Intensitas sangat tinggi, pola harmonik sangat padat, dan warna spektrogram mendekati putih atau kuning cerah.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎧 Soal 2: Penerapan Teknik Fading pada Musik\n",
    "\n",
    "### 🎵 Musik yang Dipilih:\n",
    "Untuk soal ini, saya menggunakan hasil editing musik **\"Tropical Theraphy\" dari One OK Rock** dengan durasi **30 detik**. Potongan musik ini **tidak memiliki efek fading** di bagian awal maupun akhir, sehingga sesuai dengan kriteria soal.\n",
    "\n",
    "---\n",
    "\n",
    "### 🎚️ Proses Editing:\n",
    "Saya menerapkan teknik **fading in** pada bagian awal dan **fading out** pada bagian akhir musik untuk menghasilkan transisi suara yang lebih halus. Proses fading ini dilakukan dengan menggunakan bantuan pustaka `librosa` dan `numpy`.\n",
    "\n",
    "- **Fade in**: volume suara secara bertahap meningkat di awal musik\n",
    "- **Fade out**: volume suara secara bertahap menurun di akhir musik\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 Langkah-Langkah yang Dilakukan:\n",
    "1. Saya memuat file audio `.wav` hasil editing ke dalam notebook\n",
    "2. Saya menghitung jumlah sample untuk proses fading in dan out\n",
    "3. Saya mengalikan bagian awal dan akhir dengan faktor peningkatan dan penurunan volume menggunakan array linear\n",
    "4. Saya menyimpan hasil audio yang sudah difade ke file baru\n",
    "5. Saya memvisualisasikan waveform sebelum dan sesudah diterapkan efek fade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import wave\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat audio file\n",
    "file_path = os.path.join(os.getcwd(), 'file_audio', 'tropical.wav')\n",
    "audio = AudioSegment.from_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_ms = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi waveform audio sebelum Fading\n",
    "with wave.open(file_path, 'r') as wav_file:\n",
    "    # Read frames and extract audio data\n",
    "    frames = wav_file.readframes(-1)\n",
    "    sound_info = np.frombuffer(frames, dtype=np.int16)\n",
    "    \n",
    "    # Get the frame rate (sampling rate)\n",
    "    frame_rate = wav_file.getframerate()\n",
    "    \n",
    "    # Create a time array for the x-axis\n",
    "    time = np.linspace(0, len(sound_info) / frame_rate, num=len(sound_info))\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    \n",
    "    # Plot the waveform\n",
    "    plt.plot(time, sound_info, color=\"#007ACC\")\n",
    "    \n",
    "    # Title and labels\n",
    "    plt.title('Waveform Musik 30 Detik', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Amplitudo', fontsize=14)\n",
    "    plt.xlabel('Waktu (detik)', fontsize=14)\n",
    "    \n",
    "    # Add grid with customized color and linewidth\n",
    "    plt.grid(linewidth=0.5, color='#FF6500')\n",
    "    \n",
    "    # Set tight layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi spectogram audio sebelum fading\n",
    "plt.figure(figsize=(20, 5))\n",
    "S = librosa.stft(y)\n",
    "S_db = librosa.amplitude_to_db(np.abs(S))\n",
    "\n",
    "# Hasil\n",
    "librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='log', cmap='inferno')\n",
    "plt.colorbar(format='%+0.3f dB')\n",
    "plt.title('Spektogram Musik 30 Detik', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fading Logaritmik\n",
    "def logarithmic_fade(audio, fade_in=True, duration_ms=30000):\n",
    "    steps = duration_ms // 10  # Setiap 10 ms langkah\n",
    "    start_dB = -40.0 if fade_in else 0.0  # Mulai dari -40 dB untuk fade in\n",
    "    end_dB = 0.0 if fade_in else -40.0  # Akhiri di 0 dB untuk fade in, atau turun ke -40 dB untuk fade out\n",
    "\n",
    "    faded_audio = AudioSegment.silent(duration=0)  # Mulai dengan audio kosong\n",
    "\n",
    "    for i in range(steps):\n",
    "        volume_dB = start_dB + (end_dB - start_dB) * (1 - np.log10(i + 1) / np.log10(steps + 1))\n",
    "        segment = audio[i * 10:(i + 1) * 10].apply_gain(volume_dB)  # Gunakan apply_gain() untuk perubahan volume\n",
    "        faded_audio += segment  # Gabungkan setiap segmen audio\n",
    "\n",
    "    return faded_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_fade= 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terapkan fade bawaan untuk perbandingan\n",
    "faded_in_audio_builtin = audio.fade_in(duration_fade)\n",
    "faded_out_audio_builtin = audio.fade_out(duration_fade)\n",
    "faded_in_out_audio_builtin = audio.fade_in(duration_fade).fade_out(duration_fade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menerapkan fungsi logaritmik\n",
    "faded_in_audio_log = logarithmic_fade(audio, fade_in=True, duration_ms=duration_fade)\n",
    "faded_out_audio_log = logarithmic_fade(audio, fade_in=False, duration_ms=duration_fade)\n",
    "faded_in_out_audio_log = logarithmic_fade(faded_in_audio_log, fade_in=False, duration_ms=duration_fade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menentukan jalur direktori untuk menyimpan file output\n",
    "output_dir = os.path.join(os.getcwd(), 'file_audio', 'outputfading30s')\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan hasilnya\n",
    "faded_in_audio_builtin.export(os.path.join(output_dir, 'faded_in_builtin.wav'), format=\"wav\")\n",
    "faded_out_audio_builtin.export(os.path.join(output_dir, 'faded_out_builtin.wav'), format=\"wav\")\n",
    "faded_in_audio_log.export(os.path.join(output_dir, 'faded_in_logarithmic.wav'), format=\"wav\")\n",
    "faded_out_audio_log.export(os.path.join(output_dir, 'faded_out_logarithmic.wav'), format=\"wav\")\n",
    "faded_in_out_audio_builtin.export(os.path.join(output_dir, 'faded_in_out_builtin.wav'), format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"File audio dengan efek fade in dan fade out telah disimpan!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan waveform setelah fade in\n",
    "file_in = os.path.join(os.getcwd(), output_dir, 'faded_in_builtin.wav')\n",
    "audio = AudioSegment.from_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi waveform audio fade in\n",
    "with wave.open(file_in, 'r') as wav_file:\n",
    "    frames = wav_file.readframes(-1)\n",
    "    sound_info = np.frombuffer(frames, dtype=np.int16)\n",
    "    frame_rate = wav_file.getframerate()\n",
    "    time = np.linspace(0, len(sound_info) / frame_rate, num=len(sound_info))\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(time, sound_info, color=\"#007ACC\")\n",
    "    plt.title('Waveform Musik Fade In 30 Detik', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Amplitudo')\n",
    "    plt.xlabel('Waktu (detik)')\n",
    "    plt.grid(linewidth=0.5, color='#FF6500')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan waveform setelah fade out\n",
    "file_out = os.path.join(os.getcwd(), output_dir, 'faded_out_builtin.wav')\n",
    "audio = AudioSegment.from_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi waveform audio fade out\n",
    "with wave.open(file_out, 'r') as wav_file:\n",
    "    frames = wav_file.readframes(-1)\n",
    "    sound_info = np.frombuffer(frames, dtype=np.int16)\n",
    "    frame_rate = wav_file.getframerate()\n",
    "    time = np.linspace(0, len(sound_info) / frame_rate, num=len(sound_info))\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(time, sound_info, color=\"#007ACC\")\n",
    "    plt.title('Waveform Musik Fade Out 30 Detik', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Amplitudo')\n",
    "    plt.xlabel('Waktu (detik)')\n",
    "    plt.grid(linewidth=0.5, color='#FF6500')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan waveform setelah fade in-out\n",
    "file_in_out = os.path.join(os.getcwd(), output_dir, 'faded_in_out_builtin.wav')\n",
    "audio = AudioSegment.from_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi waveform audio fade out\n",
    "with wave.open(file_in_out, 'r') as wav_file:\n",
    "    frames = wav_file.readframes(-1)\n",
    "    sound_info = np.frombuffer(frames, dtype=np.int16)\n",
    "    frame_rate = wav_file.getframerate()\n",
    "    time = np.linspace(0, len(sound_info) / frame_rate, num=len(sound_info))\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(time, sound_info, color=\"#007ACC\")\n",
    "    plt.title('Waveform Musik Fade In dan Out 30 Detik', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Amplitudo')\n",
    "    plt.xlabel('Waktu (detik)')\n",
    "    plt.grid(linewidth=0.5, color='#FF6500')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📝 Analisis Singkat:\n",
    "Dari total keseluruhan audio yaitu 30 detik, dilakukan beberapa teknik fading untuk melakukan fading selama 8 detik. Teknik ini dilakukan di awal (fading in), di akhir (fading out), dan kombinasi keduanya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎧 Soal 3: Penerapan Filter Equalisasi untuk Mengurangi Noise\n",
    "\n",
    "### 🔊 Rekaman yang Digunakan:\n",
    "Untuk soal ini, saya merekam suara berbicara di sekitar keran air yang tengah mengalir dengan durasi kurang lebih 10 detik. Rekaman ini disimpan dalam format `.wav` dan memuat noise dominan dari suara air.\n",
    "\n",
    "---\n",
    "\n",
    "### 🎚️ Proses Filtering:\n",
    "Saya menerapkan tiga jenis filter equalisasi pada rekaman untuk mengurangi noise:\n",
    "\n",
    "- **High-pass filter**: menghilangkan frekuensi rendah seperti suara air\n",
    "- **Low-pass filter**: mengurangi frekuensi tinggi seperti suara gemericik air.\n",
    "- **Band-pass filter**: mempertahankan hanya frekuensi tengah (area suara manusia)\n",
    "\n",
    "Filter dilakukan dengan pustaka `scipy.signal` dan `librosa`.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 Langkah-Langkah yang Dilakukan:\n",
    "1. Memuat file rekaman `.wav` menggunakan `librosa`\n",
    "2. Menerapkan tiga jenis filter:\n",
    "   - High-pass dengan cutoff 300 Hz\n",
    "   - Low-pass dengan cutoff 3000 Hz\n",
    "   - Band-pass antara 300–3000 Hz\n",
    "3. Membandingkan hasil filtering berdasarkan spektrogram masing-masing\n",
    "4. Menganalisis keefektifan masing-masing filter terhadap noise dan kejelasan suara\n",
    "5. Menyimpan hasil filtering terbaik ke dalam file `.wav`\n",
    "\n",
    "---\n",
    "\n",
    "### 🔬 Visualisasi Spektrogram:\n",
    "Saya menampilkan spektrogram dari keempat kondisi:\n",
    "- Spektrogram asli (tanpa filter)\n",
    "- Spektrogram setelah high-pass\n",
    "- Spektrogram setelah low-pass\n",
    "- Spektrogram setelah band-pass\n",
    "\n",
    "Visualisasi ini membantu memahami bagaimana masing-masing filter memengaruhi distribusi frekuensi pada audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import os\n",
    "import librosa\n",
    "import numpy as py\n",
    "import scipy.signal as signal\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(), 'file_audio', 'berisik.wav')\n",
    "\n",
    "# Original sampling rate\n",
    "y, sr = librosa.load(file_path, sr=None)\n",
    "print (f\"Sampling Rate: {sr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_pass_filter(audio_data, sr, cutoff=1000):\n",
    "    # Filter Design\n",
    "    b, a = signal.butter(2, cutoff, btype='high', fs=sr, output='ba')\n",
    "\n",
    "    # Filter application\n",
    "    filtered_audio = signal.lfilter(b, a, audio_data)\n",
    "\n",
    "    return filtered_audio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpassed_audio = high_pass_filter(y, sr, cutoff=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting dan Komparasi\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Time axis for plotting\n",
    "time_axis = np.linspace(0, len(y) / sr, len(y))\n",
    "\n",
    "# Plot the waveform comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(time_axis, y, label='Original', alpha=0.7)\n",
    "plt.title('Original Audio Waveform')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(time_axis, hpassed_audio, label='High-Pass Filtered', color='orange', alpha=0.7)\n",
    "plt.title('High-Pass Filtered Audio Waveform (Cutoff: 500 Hz)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid(alpha=1)\n",
    "\n",
    "# Calculate and plot the spectrogram of the original audio\n",
    "plt.subplot(2, 2, 3)\n",
    "D_original = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "librosa.display.specshow(D_original, sr=sr, x_axis='time', y_axis='log', cmap='viridis')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Original Audio Spectrogram')\n",
    "\n",
    "# Calculate and plot the spectrogram of the high-pass filtered audio\n",
    "plt.subplot(2, 2, 4)\n",
    "D_filtered = librosa.amplitude_to_db(np.abs(librosa.stft(hpassed_audio)), ref=np.max)\n",
    "librosa.display.specshow(D_filtered, sr=sr, x_axis='time', y_axis='log', cmap='viridis')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('High-Pass Filtered Audio Spectrogram')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menentukan jalur direktori untuk menyimpan file output\n",
    "output_dir = os.path.join(os.getcwd(), 'file_audio', 'outputequalization')\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered audio\n",
    "output_path = os.path.join(output_dir, 'high_pass_filtered.wav')\n",
    "sf.write(output_path, hpassed_audio, sr)\n",
    "print(f\"Filtered audio saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_pass_filter(audio_data, sr, cutoff=1000):    \n",
    "    b, a = signal.butter(2, cutoff, btype='low', fs=sr, output='ba')\n",
    "    filtered_audio = signal.lfilter(b, a, audio_data)\n",
    "    \n",
    "    return filtered_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply low pass filter to the audio\n",
    "lpassed_audio = low_pass_filter(y, sr, cutoff=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the original and low-pass filtered audio\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Time axis for plotting\n",
    "time_axis = np.linspace(0, len(y) / sr, len(y))\n",
    "\n",
    "# Plot the waveform comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(time_axis, y, label='Original', alpha=0.7)\n",
    "plt.title('Original Audio Waveform')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(time_axis, lpassed_audio, label='Low-Pass Filtered', color='green', alpha=0.7)\n",
    "plt.title('Low-Pass Filtered Audio Waveform (Cutoff: 1000 Hz)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Calculate and plot the spectrogram of the original audio\n",
    "plt.subplot(2, 2, 3)\n",
    "D_original = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "librosa.display.specshow(D_original, sr=sr, x_axis='time', y_axis='log', cmap='viridis')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Original Audio Spectrogram')\n",
    "\n",
    "# Calculate and plot the spectrogram of the low-pass filtered audio\n",
    "plt.subplot(2, 2, 4)\n",
    "D_filtered = librosa.amplitude_to_db(np.abs(librosa.stft(lpassed_audio)), ref=np.max)\n",
    "librosa.display.specshow(D_filtered, sr=sr, x_axis='time', y_axis='log', cmap='viridis')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Low-Pass Filtered Audio Spectrogram')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the low-pass filtered audio\n",
    "output_path = os.path.join(output_dir, 'low_pass_filtered.wav')\n",
    "\n",
    "sf.write(output_path, lpassed_audio, sr)\n",
    "print(f\"Low-pass filtered audio saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_pass_filter(audio_data, sr, lowcut=500, highcut=2000):\n",
    "    \n",
    "    # Create a bandpass Butterworth filter\n",
    "    b, a = signal.butter(2, [lowcut, highcut], btype='band', fs=sr, output='ba')\n",
    "    \n",
    "    # Apply the filter\n",
    "    filtered_audio = signal.lfilter(b, a, audio_data)\n",
    "    \n",
    "    return filtered_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply band pass filter to the audio\n",
    "bpassed_audio = band_pass_filter(y, sr, lowcut=200, highcut=4500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the original and band-pass filtered audio\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Plot the waveform comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(time_axis, y, label='Original', alpha=0.7)\n",
    "plt.title('Original Audio Waveform')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(time_axis, bpassed_audio, label='Band-Pass Filtered', color='purple', alpha=0.7)\n",
    "plt.title('Band-Pass Filtered Audio Waveform (500-2000 Hz)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Calculate and plot the spectrogram of the original audio\n",
    "plt.subplot(2, 2, 3)\n",
    "D_original = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "librosa.display.specshow(D_original, sr=sr, x_axis='time', y_axis='log', cmap='viridis')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Original Audio Spectrogram')\n",
    "\n",
    "# Calculate and plot the spectrogram of the band-pass filtered audio\n",
    "plt.subplot(2, 2, 4)\n",
    "D_filtered = librosa.amplitude_to_db(np.abs(librosa.stft(bpassed_audio)), ref=np.max)\n",
    "librosa.display.specshow(D_filtered, sr=sr, x_axis='time', y_axis='log', cmap='viridis')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Band-Pass Filtered Audio Spectrogram')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the band-pass filtered audio\n",
    "output_path = os.path.join(output_dir, 'band_pass_filtered.wav')\n",
    "sf.write(output_path, bpassed_audio, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📝 Analisis Singkat:\n",
    "\n",
    "- **Jenis noise**: Pada rekaman suara air, suara aliran air dominan berada pada **frekuensi rendah** (di bawah 500 Hz) dan **frekuensi tinggi** (di atas 4000 Hz). Frekuensi rendah biasanya berupa gema atau gemuruh aliran air, sementara frekuensi tinggi dapat mencakup percikan air atau suara air yang berdesir.\n",
    "\n",
    "- **Filter paling efektif**: \n",
    "  - **Band-pass filter (500–2000 Hz)** paling efektif untuk mengurangi noise yang muncul, karena filter ini memungkinkan suara manusia (yang dominan di rentang frekuensi 300–3000 Hz) untuk tetap terdengar jelas sementara suara air yang berada di luar rentang ini akan dikurangi.\n",
    "  - Filter **Low-pass** dengan cutoff rendah dan **High-pass** dengan cutoff tinggi dapat mengurangi suara air, tetapi band-pass lebih fokus pada pemrosesan suara ucapan.\n",
    "\n",
    "- **Hasil filtering terbaik**:\n",
    "  - **Suara bicara** menjadi lebih jelas dan terfokus. Suara air yang mengganggu, baik gemuruh maupun percikan, berkurang signifikan.\n",
    "  - **Suara air** berkurang terutama pada frekuensi rendah dan tinggi, yang memperbaiki kualitas suara ucapan.\n",
    "  - **Transkripsi ucapan** jadi lebih mudah dilakukan karena suara latar (air) sudah dikurangi dengan efektif.\n",
    "\n",
    "- **Nilai cutoff yang memberikan hasil terbaik**:\n",
    "  - **Low-pass filter (cutoff 1000 Hz)** sangat efektif untuk mengurangi noise pada frekuensi tinggi.\n",
    "  - **High-pass filter (cutoff 500 Hz)** efektif untuk mengurangi suara di bawah rentang ucapan manusia.\n",
    "  - **Band-pass filter (cutoff 500–2000 Hz)** memberikan hasil paling optimal karena hanya melewatkan rentang frekuensi yang relevan untuk ucapan manusia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎧 Soal 4: Pitch Shifting Efek Chipmunk\n",
    "\n",
    "### 🎙️ Rekaman yang Digunakan:\n",
    "Untuk soal ini, saya menggunakan rekaman suara dari Soal 1. Tujuannya adalah menerapkan **pitch shifting ke atas** untuk menciptakan efek **chipmunk** atau suara yang lebih tinggi dan lucu.\n",
    "\n",
    "---\n",
    "\n",
    "### 🎚️ Proses Pitch Shifting:\n",
    "Saya menggunakan pustaka `librosa` untuk melakukan pitch shifting dengan parameter berikut:\n",
    "\n",
    "- **+7 semitone**: menaikkan pitch sedang\n",
    "- **+12 semitone**: menaikkan pitch satu oktaf penuh\n",
    "\n",
    "Pitch shifting dilakukan tanpa mengubah kecepatan (durasi tetap).\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 Langkah-Langkah yang Dilakukan:\n",
    "1. Memuat rekaman suara dari Soal 1\n",
    "2. Menerapkan pitch shifting sebanyak +7 dan +12 semitone\n",
    "3. Visualisasi waveform dan spektrogram:\n",
    "   - Sebelum pitch shifting\n",
    "   - Setelah pitch shifting +7\n",
    "   - Setelah pitch shifting +12\n",
    "4. Menggabungkan hasil pitch shifting +7 dan +12 menjadi satu file audio\n",
    "5. Menganalisis perbedaan kualitas suara dan tampilan visual\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 Visualisasi:\n",
    "Saya menampilkan:\n",
    "- **Waveform** dan **spektrogram** sebelum dan sesudah pitch shifting\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### 💾 Output:\n",
    "Hasil akhir disimpan sebagai:\n",
    "📁 `chipmunk_pitch_audio.wav`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path setup\n",
    "file_path = os.path.join(os.getcwd(), 'file_audio', 'berita.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menyalakan audio dengan sr original\n",
    "y, sr = librosa.load(file_path, sr=None)\n",
    "print(f\"Sampling Rate: {sr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load file dengan librosa\n",
    "audio_data, sr = librosa.load(file_path, sr=None)\n",
    "print(f\"Durasi rekaman: {librosa.get_duration(y=audio_data, sr=sr):.2f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Player suara asli\n",
    "display(Audio(audio_data, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi visualisasi\n",
    "def plot_waveform_spectrogram(y, sr, title):\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(12, 6))\n",
    "    \n",
    "    # Waveform\n",
    "    librosa.display.waveshow(y, sr=sr, ax=axs[0], alpha=0.7)\n",
    "    axs[0].set_title(f\"Waveform - {title}\")\n",
    "    \n",
    "    # Spectrogram\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "    img = librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', ax=axs[1])\n",
    "    axs[1].set_title(f\"Spectrogram - {title}\")\n",
    "    fig.colorbar(img, ax=axs[1], format=\"%+2.0f dB\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize original audio\n",
    "plot_waveform_spectrogram(audio_data, sr, 'Original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitch shifting using librosa.effects.pitch_shift\n",
    "def pitch_shift_librosa(y, sr, n_steps):\n",
    "    # Apply pitch shift using librosa.effects.pitch_shift (with sr argument as a keyword)\n",
    "    y_shifted = librosa.effects.pitch_shift(y, sr=sr, n_steps=n_steps)  # Apply pitch shift\n",
    "    return y_shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitch shifting manually by +12 and +7 semitones\n",
    "pitch_up_12 = pitch_shift_librosa(audio_data, sr, 12)  # Pitch +12 semitones\n",
    "pitch_up_7 = pitch_shift_librosa(audio_data, sr, 7)    # Pitch +7 semitones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize pitch shifted audios\n",
    "plot_waveform_spectrogram(pitch_up_12, sr, 'Pitch +12')\n",
    "plot_waveform_spectrogram(pitch_up_7, sr, 'Pitch +7')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pitch shifted audios\n",
    "output_dir = os.path.join(os.getcwd(), 'file_audio', 'output_pitch')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Use soundfile to save the shifted pitch audios (librosa no longer has write_wav)\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pitch_12_path = os.path.join(output_dir, 'berita_pitch_up_12.wav')\n",
    "pitch_7_path = os.path.join(output_dir, 'berita_pitch_up_7.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save pitch shifted audios using soundfile\n",
    "sf.write(pitch_12_path, pitch_up_12, sr)\n",
    "sf.write(pitch_7_path, pitch_up_7, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play audio files\n",
    "print(\"Original Audio:\")\n",
    "display(Audio(audio_data, rate=sr))\n",
    "\n",
    "print(\"Pitch +12 Audio:\")\n",
    "display(Audio(pitch_up_12, rate=sr))\n",
    "\n",
    "print(\"Pitch +7 Audio:\")\n",
    "display(Audio(pitch_up_7, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both pitch-shifted audios into one file\n",
    "combined_audio = np.concatenate([pitch_up_12, pitch_up_7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the combined audio\n",
    "combined_path = os.path.join(output_dir, 'combined_pitch_audio.wav')\n",
    "sf.write(combined_path, combined_audio, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Combined Audio: {combined_path}\")\n",
    "display(Audio(combined_audio, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📝 Analisis:\n",
    "🔊 Pitch Shifting\n",
    "\n",
    "- Menggunakan `librosa.effects.pitch_shift()` dengan parameter:\n",
    "  - `n_steps=7` (menaikkan pitch sedang)\n",
    "  - `n_steps=12` (menaikkan pitch satu oktaf penuh)\n",
    "- Tujuan: Mengubah pitch suara asli tanpa mengubah durasi (kecepatan tetap).\n",
    "\n",
    "---\n",
    "\n",
    "🎨 Efek Visual (Spektrogram)\n",
    "\n",
    "- Frekuensi pada **spektrogram** bergeser ke atas ketika pitch diubah.\n",
    "- Semakin tinggi pitch:\n",
    "  - Frekuensi menjadi lebih terkonsentrasi pada bagian atas rentang spektrum.\n",
    "  - Warna dan pola pada spektrogram menunjukkan peningkatan aktivitas di frekuensi tinggi.\n",
    "\n",
    "---\n",
    "\n",
    "🎧 Efek Audio\n",
    "\n",
    "- **Pitch lebih tinggi** menghasilkan suara yang lebih **tajam** dan terdengar lebih **cepat**, seperti suara **chipmunk**.\n",
    "- Suara tetap **dapat dipahami**, namun:\n",
    "  - **Kehilangan karakter alami**\n",
    "  - Terasa sebagai **efek suara lucu atau kreatif**\n",
    "\n",
    "---\n",
    "\n",
    "💡 Penggunaan Pitch Shifting\n",
    "\n",
    "- Sangat berguna untuk **efek suara kreatif**\n",
    "- Umumnya dipakai di:\n",
    "  - Industri hiburan (kartun, karakter suara unik)\n",
    "  - Pengolahan audio dalam media kreatif (konten video, podcast, musik eksperimental)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎧 Soal 5: Normalisasi dan Loudness Optimization\n",
    "\n",
    "### 🎙️ Rekaman yang Digunakan:\n",
    "Untuk soal ini, saya menggunakan hasil audio dari Soal 4 yang telah di-*pitch shift* menjadi suara seperti chipmunk dan telah digabungkan menjadi satu file (`chipmunk_pitch_audio.wav`).\n",
    "\n",
    "---\n",
    "\n",
    "### 🎚️ Tujuan:\n",
    "Melakukan proses:\n",
    "- **Normalisasi**: mengatur gain agar audio mencapai level tertentu\n",
    "- **Loudness Optimization**: menyesuaikan loudness rata-rata ke **target -18 LUFS** untuk kenyamanan dengar\n",
    "\n",
    "---\n",
    "\n",
    "### 🔧 Metode:\n",
    "- Saya menggunakan pustaka `pyloudnorm` untuk menghitung dan mengoptimalkan **LUFS** (Loudness Units Full Scale)\n",
    "- Proses normalisasi ini berbasis pada loudness persepsi manusia, bukan hanya *peak amplitude*\n",
    "- Dibandingkan dengan normalisasi peak tradisional\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 Langkah-Langkah yang Dilakukan:\n",
    "1. Memuat file audio hasil pitch shifting\n",
    "2. Menghitung loudness awal (LUFS)\n",
    "3. Menerapkan normalisasi agar target loudness = -18 LUFS\n",
    "4. Visualisasi waveform dan spektrogram:\n",
    "   - Sebelum normalisasi\n",
    "   - Sesudah normalisasi\n",
    "5. Menganalisis perubahan kualitas suara\n",
    "\n",
    "---\n",
    "\n",
    "### 💾 Output:\n",
    "Hasil audio setelah normalisasi disimpan sebagai:\n",
    "📁 `chipmunk_loudness_normalized.wav`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the combined chipmunk audio\n",
    "file_path = os.path.join(os.getcwd(), 'file_audio', 'output_pitch', 'combined_pitch_audio.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the audio file\n",
    "audio_data, sr = librosa.load(file_path, sr=None)\n",
    "print(f\"Sampling Rate: {sr}\")\n",
    "print(f\"Duration of the audio: {librosa.get_duration(y=audio_data, sr=sr):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the original audio\n",
    "display(Audio(audio_data, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot waveform and spectrogram\n",
    "def plot_waveform_spectrogram(y, sr, title):\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(12, 6))\n",
    "    \n",
    "    # Waveform\n",
    "    librosa.display.waveshow(y, sr=sr, ax=axs[0], alpha=0.7)\n",
    "    axs[0].set_title(f\"Waveform - {title}\")\n",
    "    \n",
    "    # Spectrogram\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "    img = librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', ax=axs[1])\n",
    "    axs[1].set_title(f\"Spectrogram - {title}\")\n",
    "    fig.colorbar(img, ax=axs[1], format=\"%+2.0f dB\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize original audio\n",
    "plot_waveform_spectrogram(audio_data, sr, 'Original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate initial loudness (LUFS) using librosa\n",
    "def calculate_loudness(y, sr):\n",
    "    # Using RMS energy as a proxy for loudness (simplified)\n",
    "    rms = librosa.feature.rms(y=y)[0]\n",
    "    loudness = 20 * np.log10(np.mean(rms))  # Convert RMS to dB\n",
    "    return loudness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "initial_loudness = calculate_loudness(audio_data, sr)\n",
    "print(f\"Initial loudness: {initial_loudness:.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Calculate the gain needed to reach target loudness (-18 LUFS)\n",
    "target_loudness = -18  # Target loudness in dB\n",
    "gain_needed = target_loudness - initial_loudness\n",
    "print(f\"Gain needed to reach {target_loudness} dB: {gain_needed:.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the audio by applying the calculated gain\n",
    "def normalize_audio(audio_data, gain_db):\n",
    "    # Convert dB to linear gain\n",
    "    gain_linear = 10 ** (gain_db / 20.0)\n",
    "    \n",
    "    # Apply gain\n",
    "    normalized_audio = audio_data * gain_linear\n",
    "    \n",
    "    # Clip to prevent distortion\n",
    "    normalized_audio = np.clip(normalized_audio, -1.0, 1.0)\n",
    "    \n",
    "    return normalized_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply the gain to normalize the audio\n",
    "normalized_audio = normalize_audio(audio_data, gain_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Visualize the normalized audio\n",
    "plot_waveform_spectrogram(normalized_audio, sr, f'Normalized to {target_loudness} LUFS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the normalized audio\n",
    "output_dir = os.path.join(os.getcwd(), 'file_audio', 'output_loudness')\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_audio_path = os.path.join(output_dir, 'chipmunk_loudness_normalized_manual.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the normalized audio using soundfile\n",
    "sf.write(normalized_audio_path, normalized_audio, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the audio\n",
    "print(f\"🔊 Normalized Audio: {normalized_audio_path}\")\n",
    "display(Audio(normalized_audio, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📊 Analisis:\n",
    "\n",
    "1. **Perubahan Dinamika Suara yang Terjadi**:\n",
    "- **Sebelum normalisasi**: Dari gambar waveform dan spektrogram, dapat dilihat bahwa amplitudo suara bervariasi dengan cukup lebar. Terdapat bagian-bagian di mana suara sangat kecil (berada di bawah garis nol), serta bagian yang lebih keras dengan amplitudo yang jauh lebih tinggi.\n",
    "- **Setelah normalisasi loudness**: Amplitudo suara menjadi lebih konsisten dan terkontrol. Hal ini mengindikasikan bahwa suara yang lebih keras telah ditekan, sementara suara yang lebih pelan telah diperkuat untuk mencapai level loudness yang lebih seragam dan sesuai target LUFS.\n",
    "\n",
    "2. **Perbedaan antara Normalisasi Peak dan Normalisasi LUFS**:\n",
    "- **Normalisasi Peak**: Biasanya hanya berfokus pada puncak amplitudo tertinggi dari rekaman. Proses ini dapat menyebabkan distorsi jika amplitudo puncaknya sangat tinggi, tetapi tidak memberikan kontrol terhadap keseluruhan dinamika audio.\n",
    "- **Normalisasi LUFS**: Berfokus pada loudness perseptual, yaitu seberapa keras suara terdengar bagi pendengar. Normalisasi LUFS lebih memperhatikan persepsi pendengaran manusia daripada hanya menilai amplitudo puncak, sehingga menghasilkan suara yang lebih konsisten dengan kualitas lebih terjaga dan menghindari distorsi.\n",
    "\n",
    "3. **Bagaimana Kualitas Suara Berubah Setelah Proses Normalisasi dan Loudness Optimization**:\n",
    "- **Suara menjadi lebih konsisten**: Setelah normalisasi LUFS, perbedaan antara bagian suara yang keras dan yang pelan menjadi lebih halus, menghasilkan rekaman yang lebih mudah didengarkan dalam lingkungan yang bising.\n",
    "- **Penguatan suara pelan dan penurunan suara keras**: Suara yang tadinya terlalu pelan kini lebih terdengar jelas, sementara bagian yang terlalu keras lebih terkontrol.\n",
    "- **Kualitas suara tetap terjaga**: Meskipun terdapat perubahan dalam tingkat loudness, kualitas suara, terutama dalam hal kejelasan ucapan atau instrumen, tetap terjaga tanpa adanya distorsi signifikan.\n",
    "\n",
    "4. **Kelebihan dan Kekurangan dari Pengoptimalan Loudness dalam Konteks Rekaman Suara**:\n",
    "\n",
    "**Kelebihan**:\n",
    "- **Konsistensi**: Mengoptimalkan loudness dengan menggunakan LUFS membuat audio lebih konsisten dan dapat dipahami dengan lebih jelas, terutama dalam konteks rekaman radio atau podcast.\n",
    "- **Kontrol yang lebih baik atas dinamika**: Menggunakan LUFS memberikan kontrol lebih baik terhadap dinamika suara, sehingga tidak ada bagian suara yang terlalu keras atau terlalu pelan.\n",
    "- **Penggunaan standar industri**: LUFS telah menjadi standar di banyak platform dan aplikasi streaming untuk memberikan pengalaman mendengarkan yang lebih seimbang dan nyaman.\n",
    "\n",
    "**Kekurangan**:\n",
    "- **Distorsi pada suara yang sangat keras**: Jika level audio sangat tinggi sebelum normalisasi, pengurangan loudness untuk mencapai target LUFS bisa menyebabkan suara terdengar datar dan kehilangan ekspresinya.\n",
    "- **Mungkin mengurangi karakter audio**: Kadang-kadang normalisasi yang terlalu ketat dapat membuat audio terasa kurang alami, menghilangkan keunikan suara asli atau dinamika musik yang seharusnya ada.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📚 Kredit dan Referensi\n",
    "\n",
    "### 🔗 Referensi Pembelajaran:\n",
    "- [Modul Hands-On 1 (Audio Processing - IF4021)](https://github.com/informatika-itera/if4021-handson/blob/main/1_Module_Audio.ipynb)\n",
    "- [Matplotlib Colormap Reference](https://matplotlib.org/stable/gallery/color/colormap_reference.html)\n",
    "\n",
    "---\n",
    "\n",
    "### 💬 Percakapan dengan ChatGPT:\n",
    "- [Riwayat Diskusi di Google Drive](https://drive.google.com/drive/folders/1gPmMH7YiiDmYg40ca8kqykiKrwCnD-zK?usp=sharing)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
